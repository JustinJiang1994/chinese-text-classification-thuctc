#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é¢„å¤„ç†è¿è¡Œè„šæœ¬
ä½¿ç”¨é…ç½®æ–‡ä»¶è¿›è¡Œæ•°æ®é¢„å¤„ç†
"""

import json
import argparse
from pathlib import Path
from data_preprocessor import DataPreprocessor
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def load_config(config_file: str = "config/preprocessing_config.json") -> dict:
    """
    åŠ è½½é…ç½®æ–‡ä»¶
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        é…ç½®å­—å…¸
    """
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        logger.info(f"æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
        return config
    except Exception as e:
        logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        raise

def run_preprocessing(config: dict, input_file: str = None):
    """
    è¿è¡Œæ•°æ®é¢„å¤„ç†
    
    Args:
        config: é…ç½®å­—å…¸
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ï¼‰
    """
    # è·å–é…ç½®
    preprocess_config = config['data_preprocessing']
    experiment_config = config['experiment_settings']
    
    # ç¡®å®šè¾“å…¥æ–‡ä»¶
    if input_file is None:
        if experiment_config['use_sample_data']:
            input_file = experiment_config['sample_data_file']
        else:
            input_file = experiment_config['full_data_file']
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(input_file).exists():
        logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return
    
    # åˆ›å»ºé¢„å¤„ç†å™¨
    preprocessor = DataPreprocessor(
        stopwords_file=preprocess_config['stopwords_file'],
        random_seed=preprocess_config['random_seed']
    )
    
    # æ›´æ–°é…ç½®
    preprocessor.config.update({
        'min_text_length': preprocess_config['text_filtering']['min_text_length'],
        'max_text_length': preprocess_config['text_filtering']['max_text_length'],
        'train_ratio': preprocess_config['data_splitting']['train_ratio'],
        'val_ratio': preprocess_config['data_splitting']['val_ratio'],
        'test_ratio': preprocess_config['data_splitting']['test_ratio'],
        'stratify': preprocess_config['data_splitting']['stratify'],
        'remove_empty': preprocess_config['text_filtering']['remove_empty']
    })
    
    # è¿è¡Œé¢„å¤„ç†æµç¨‹
    output_dir = preprocess_config['output']['output_dir']
    stats = preprocessor.preprocess_pipeline(input_file, output_dir)
    
    logger.info(f"æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
    logger.info(f"è¾“å…¥æ–‡ä»¶: {input_file}")
    logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
    logger.info(f"éšæœºç§å­: {preprocess_config['random_seed']}")
    
    return stats

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ•°æ®é¢„å¤„ç†è„šæœ¬')
    parser.add_argument('--config', type=str, default='config/preprocessing_config.json',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--input', type=str, default=None,
                       help='è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ï¼‰')
    parser.add_argument('--use-sample', action='store_true',
                       help='ä½¿ç”¨æ ·æœ¬æ•°æ®ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®ï¼‰')
    parser.add_argument('--use-full', action='store_true',
                       help='ä½¿ç”¨å®Œæ•´æ•°æ®ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®ï¼‰')
    
    args = parser.parse_args()
    
    try:
        # åŠ è½½é…ç½®
        config = load_config(args.config)
        
        # å¤„ç†å‘½ä»¤è¡Œå‚æ•°
        if args.use_sample:
            config['experiment_settings']['use_sample_data'] = True
        elif args.use_full:
            config['experiment_settings']['use_sample_data'] = False
        
        # è¿è¡Œé¢„å¤„ç†
        stats = run_preprocessing(config, args.input)
        
        if stats:
            print(f"\nâœ… é¢„å¤„ç†æˆåŠŸå®Œæˆï¼")
            print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
            print(f"   - åŸå§‹æ•°æ®: {stats['original_count']} æ¡")
            print(f"   - æ¸…æ´—åæ•°æ®: {stats['cleaned_count']} æ¡")
            print(f"   - è®­ç»ƒé›†: {stats['train_count']} æ¡")
            print(f"   - éªŒè¯é›†: {stats['val_count']} æ¡")
            print(f"   - æµ‹è¯•é›†: {stats['test_count']} æ¡")
            print(f"   - å¤„ç†æ—¶é—´: {stats['processing_time']:.2f} ç§’")
        
    except Exception as e:
        logger.error(f"é¢„å¤„ç†å¤±è´¥: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main()) 